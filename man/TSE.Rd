% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/wflows-emase.R
\name{TSE}
\alias{TSE}
\title{Time Series Ensemble}
\usage{
TSE(form, train, test, learner = NULL, learner.pars = NULL,
  varying.embed = TRUE, varying.trainwindow = TRUE, ma.N = NULL,
  committee.ratio = NULL, aggregationFUN, verbose = TRUE,
  modelOutput = FALSE, ...)
}
\arguments{
\item{form}{Formula}

\item{train}{embedded time series used for training the base learners}

\item{test}{embedded time series used for testing}

\item{learner}{Character vector describing the base algorithms to be trained.
Current available implemented models are:
\describe{
   \item{MARS}{Multivariate Adaptive Regression Splines from \strong{earth} package}
   \item{PPR}{Projection Pursuit Regression from \strong{stats} package}
   \item{baggedtrees}{For a bagging ensemble for time series forecasting tasks
    (Oliveira and Torgo, 2014)}
   \item{SVM}{Support Vector Machines from \strong{kernlab} package}
   \item{GP}{Gaussian Processes from \strong{kernlab} package}
   \item{FFNN}{Feed Forward Neural Networks from \strong{nnet} package}
   \item{SVM}{Support Vector Machines from \strong{kernlab} package}
   \item{Cubist}{Rule-based Regression from \strong{Cubist} package}
   \item{RandomForest}{Random Forests from \strong{ranger} package}
   \item{GBM}{Generalized Boosted Regression from \strong{gbm} package}
   \item{GLM}{Generalized Linear Models (e.g. Ridge regression, LASSO, Elastic-Net)
   from \strong{glmnet} package}
   \item{SAE}{Stacked Autoencoder from \strong{deepnet} package}
}}

\item{learner.pars}{Named list describing the parameter of the \code{learner}. Below are
described some examples.}

\item{varying.embed}{Logical: Should different embedding dimensions be used. Defaults to TRUE.}

\item{varying.trainwindow}{Logical: Should varying training windows be used. Defaults to TRUE.}

\item{ma.N}{Integer: Number of periods to average over when computing MASE.}

\item{committee.ratio}{A numeric value between 0 and 1 representing the ratio
of base learners that comprise the committee at each prediction time.
If \code{committee.ratio} equals, say, 0.2, at time \emph{t}, the ensemble will the
20\% best base learners up to time \emph{t - 1}.}

\item{aggregationFUN}{The function name used to combine the base learners. See}

\item{verbose}{If TRUE, the status of the training of base learners is printed to the console.}

\item{modelOutput}{Logical. If TRUE, the methods applied to \code{tsensembler-class} return
a predictive model ensemble. Otherwise, it returns performance statistics based on
\code{\link[performanceEstimation]{performanceEstimation}}.}

\item{...}{Further parameters to pass to \code{TSE}}
}
\value{
a list containing the true values and predicted values for test set
}
\description{
This function comprises the pipeline used to construct the
time series ensemble.
}
\examples{
\dontrun{
workflow <- Workflow(wf = 'TSE',
                    learner = c('MARS', 'PPR'),
                    learner.pars = list(mars = list(nk = c(5, 2),
                                                    degree= c(3, 4)),
                                        ppr = list(nterms = c(2,3,4))),
                    varying.embed = TRUE,
                    varying.trainwindow = FALSE,
                    committee.ratio = .1,
                    aggregationFUN = "regret",
                    verbose = FALSE)
}

}
\seealso{
\code{\link{ensembler}} for details on the method that encapsulates this
workflow.
}

